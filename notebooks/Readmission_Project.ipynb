{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30-Day Hospital Readmission Risk — Clinical Analytics Notebook\n",
    "\n",
    "**Clinical aim.** Estimate 30-day readmission risk at discharge to prioritize proactive outreach (early clinic visit, medication reconciliation, home health). The model is designed to support value-based care and reduce avoidable readmissions.\n",
    "\n",
    "**Dataset.** `data/hospital_readmissions_30k.csv`  \n",
    "**Outcome.** `readmitted_30_days` ∈ {Yes, No} (mapped to 1/0)  \n",
    "**Repository.** https://github.com/albertokabore/Hospital-Readmission-Prediction\n",
    "\n",
    "**Decision framing.**  \n",
    "- Primary: *Recall (Sensitivity)* — identify high-risk patients to avoid missed opportunities.  \n",
    "- Secondary: *Precision* — efficient use of follow-up resources.  \n",
    "- Summary: AUROC and AUPRC given class imbalance.\n",
    "\n",
    "**Method overview.**  \n",
    "- Robust preprocessing (impute, encode, scale).  \n",
    "- Baselines + ensembles (DT, RF, GB, AdaBoost, Bagging, XGBoost).  \n",
    "- Imbalance strategies (SMOTE, undersampling).  \n",
    "- Hyperparameter tuning with `RandomizedSearchCV`.  \n",
    "- Interpretability (feature importance / coefficients).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.2.2 seaborn==0.13.1 matplotlib==3.7.1 numpy==1.25.2 pandas==1.5.3 imbalanced-learn==0.10.1 xgboost==2.0.3 -q --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.2.2 seaborn==0.13.1 matplotlib==3.7.1 numpy==1.25.2 pandas==1.5.3 imbalanced-learn==0.10.1 xgboost==2.0.3 -q --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade -q threadpoolctl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# To tune model, get different metric scores, and split data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     f1_score,\n\u001b[32m     12\u001b[39m     accuracy_score,\n\u001b[32m     13\u001b[39m     recall_score,\n\u001b[32m     14\u001b[39m     precision_score,\n\u001b[32m     15\u001b[39m     confusion_matrix,\n\u001b[32m     16\u001b[39m     roc_auc_score,\n\u001b[32m     17\u001b[39m     ConfusionMatrixDisplay,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, StratifiedKFold, cross_val_score\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# To be used for data scaling and one hot encoding\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Libraries to help with reading and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libraries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To tune model, get different metric scores, and split data\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# To be used for data scaling and one hot encoding\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# To impute missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# To oversample and undersample data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# To do hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# To help with model building\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Additional essentials\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay\n",
    "\n",
    "# Display and warnings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RSEED = 42\n",
    "sns.set(context=\"notebook\", style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Clinical Context & Business Value\n",
    "\n",
    "Readmissions within 30 days are a preventable harm and a cost driver. CMS penalizes excessive readmissions; health systems seek to target high-risk discharges for early follow-up and service coordination.  \n",
    "**Clinical question:** who is most likely to be readmitted in the next 30 days?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "FILE_NAME = \"hospital_readmissions_30k.csv\"\n",
    "TARGET = \"readmitted_30_days\"\n",
    "\n",
    "csv_path = DATA_PATH / FILE_NAME\n",
    "assert csv_path.exists(), f\"Dataset not found: {csv_path}. Place the CSV under data/.\"\n",
    "\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Understanding\n",
    "\n",
    "We profile schema, missingness, and the outcome distribution to confirm problem framing (binary classification with class imbalance is expected in clinical data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### schema & missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema overview\n",
    "buf = []\n",
    "df.info(buf=buf.append)\n",
    "print(\"\\n\".join(buf))\n",
    "\n",
    "# Missingness\n",
    "miss = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"\\nColumns with missing values (top 20):\")\n",
    "display(miss[miss > 0].head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outcome normalization & class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize outcome to {0,1}\n",
    "y_raw = df[TARGET].astype(str).str.strip().str.title()\n",
    "y = y_raw.map({\"Yes\": 1, \"No\": 0}).astype(int)\n",
    "X = df.drop(columns=[TARGET])\n",
    "\n",
    "print(f\"Positive rate (Yes): {y.mean():.3f}\")\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(x=y_raw)\n",
    "plt.title(\"Outcome distribution (30-day readmission)\")\n",
    "plt.xlabel(TARGET)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Clinical Feature Review & EDA\n",
    "\n",
    "We separate numeric and categorical features, summarize distributions, and inspect clinically relevant categories (e.g., discharge destination) where present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature typing & quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "print(f\"Categorical features: {len(cat_cols)}\")\n",
    "print(f\"Numeric features:     {len(num_cols)}\")\n",
    "\n",
    "# Numeric summary\n",
    "if num_cols:\n",
    "    display(X[num_cols].describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95]).T)\n",
    "\n",
    "# Correlation (numeric only)\n",
    "if len(num_cols) > 1:\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(X[num_cols].corr(numeric_only=True), cmap=\"coolwarm\", center=0)\n",
    "    plt.title(\"Correlation heatmap (numeric features)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Selected categorical peeks if present\n",
    "for c in [\"gender\", \"discharge_destination\", \"diabetes\", \"hypertension\"]:\n",
    "    if c in X.columns:\n",
    "        print(f\"\\n{c} (top categories):\")\n",
    "        display(X[c].value_counts(dropna=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Modeling Strategy\n",
    "\n",
    "- **Problem type:** binary classification with class imbalance.  \n",
    "- **Preprocessing:** impute numeric (median); impute categorical (most frequent) + one-hot encoding; scaling (we use both StandardScaler and MinMaxScaler).  \n",
    "- **Models:** DT, RF, GB, AdaBoost, Bagging, XGBoost.  \n",
    "- **Imbalance handling:** SMOTE oversampling and random undersampling (inside pipeline to avoid leakage).  \n",
    "- **Selection:** AUROC and AUPRC on held-out test set; recall prioritized for clinical sensitivity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric summary\n",
    "display(X[num_cols].describe(percentiles=[0.01, 0.25, 0.5, 0.75, 0.99]).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RSEED, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing: Standard & MinMax pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_standard = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "numeric_minmax = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "])\n",
    "\n",
    "categorical = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess_standard = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_standard, num_cols),\n",
    "        (\"cat\", categorical, cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess_minmax = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_minmax, num_cols),\n",
    "        (\"cat\", categorical, cat_cols),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(pipe, X_te, y_te, name=\"Model\"):\n",
    "    if hasattr(pipe.named_steps[\"clf\"], \"predict_proba\"):\n",
    "        proba = pipe.predict_proba(X_te)[:, 1]\n",
    "    else:\n",
    "        proba = pipe.decision_function(X_te)\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "    auc = roc_auc_score(y_te, proba)\n",
    "    acc = accuracy_score(y_te, pred)\n",
    "    rec = recall_score(y_te, pred)\n",
    "    pre = precision_score(y_te, pred)\n",
    "    f1  = f1_score(y_te, pred)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"AUROC: {auc:.3f} | ACC: {acc:.3f} | P: {pre:.3f} | R: {rec:.3f} | F1: {f1:.3f}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_te, pred, digits=3))\n",
    "\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_te, pred)).plot(cmap=\"Blues\")\n",
    "    plt.title(f\"{name} — Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    RocCurveDisplay.from_predictions(y_te, proba)\n",
    "    plt.title(f\"{name} — ROC Curve\")\n",
    "    plt.show()\n",
    "\n",
    "    PrecisionRecallDisplay.from_predictions(y_te, proba)\n",
    "    plt.title(f\"{name} — Precision-Recall Curve\")\n",
    "    plt.show()\n",
    "\n",
    "    return {\"AUROC\": auc, \"ACC\": acc, \"P\": pre, \"R\": rec, \"F1\": f1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baselines on StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=RSEED),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=300, random_state=RSEED, n_jobs=-1),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=RSEED),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=RSEED),\n",
    "    \"Bagging_DT\": BaggingClassifier(\n",
    "        base_estimator=DecisionTreeClassifier(random_state=RSEED),\n",
    "        n_estimators=50, random_state=RSEED, n_jobs=-1\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        random_state=RSEED, n_estimators=300, learning_rate=0.1,\n",
    "        subsample=0.9, colsample_bytree=0.9, max_depth=6,\n",
    "        eval_metric=\"logloss\", n_jobs=-1\n",
    "    ),\n",
    "}\n",
    "\n",
    "results_std = {}\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([(\"prep\", preprocess_standard), (\"clf\", clf)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    metrics = evaluate_model(pipe, X_test, y_test, name=f\"{name} (std)\")\n",
    "    results_std[name] = metrics\n",
    "\n",
    "pd.DataFrame(results_std).T.sort_values(\"AUROC\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baselines on MinMaxScaler to use MinMax explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mm = {}\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([(\"prep\", preprocess_minmax), (\"clf\", clf)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    metrics = evaluate_model(pipe, X_test, y_test, name=f\"{name} (minmax)\")\n",
    "    results_mm[name] = metrics\n",
    "\n",
    "pd.DataFrame(results_mm).T.sort_values(\"AUROC\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imbalance handling: SMOTE & undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build resampling pipelines for strong models (RF and XGB)\n",
    "rf_smote = ImbPipeline(steps=[\n",
    "    (\"prep\", preprocess_standard),\n",
    "    (\"smote\", SMOTE(random_state=RSEED)),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=400, random_state=RSEED, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "rf_under = ImbPipeline(steps=[\n",
    "    (\"prep\", preprocess_standard),\n",
    "    (\"under\", RandomUnderSampler(random_state=RSEED)),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=400, random_state=RSEED, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "xgb_smote = ImbPipeline(steps=[\n",
    "    (\"prep\", preprocess_standard),\n",
    "    (\"smote\", SMOTE(random_state=RSEED)),\n",
    "    (\"clf\", XGBClassifier(\n",
    "        objective=\"binary:logistic\", eval_metric=\"logloss\",\n",
    "        random_state=RSEED, n_estimators=300, learning_rate=0.1,\n",
    "        subsample=0.9, colsample_bytree=0.9, max_depth=6, n_jobs=-1\n",
    "    )),\n",
    "])\n",
    "\n",
    "for label, pipe in {\n",
    "    \"RF + SMOTE\": rf_smote,\n",
    "    \"RF + UnderSample\": rf_under,\n",
    "    \"XGB + SMOTE\": xgb_smote,\n",
    "}.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    _ = evaluate_model(pipe, X_test, y_test, name=label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameter tuning with RandomizedSearchCV for XGB + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_base = ImbPipeline(steps=[\n",
    "    (\"prep\", preprocess_standard),\n",
    "    (\"smote\", SMOTE(random_state=RSEED)),\n",
    "    (\"clf\", XGBClassifier(\n",
    "        objective=\"binary:logistic\", eval_metric=\"logloss\",\n",
    "        random_state=RSEED, n_jobs=-1\n",
    "    )),\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    \"clf__n_estimators\": [200, 300, 400, 600, 800],\n",
    "    \"clf__max_depth\": [3, 4, 5, 6, 8],\n",
    "    \"clf__learning_rate\": [0.03, 0.05, 0.1, 0.2],\n",
    "    \"clf__subsample\": [0.7, 0.8, 0.9, 1.0],\n",
    "    \"clf__colsample_bytree\": [0.7, 0.8, 0.9, 1.0],\n",
    "    \"clf__min_child_weight\": [1, 3, 5, 7],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RSEED)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    random_state=RSEED,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best CV AUROC:\", search.best_score_)\n",
    "print(\"Best params:\", search.best_params_)\n",
    "\n",
    "xgb_tuned = search.best_estimator_\n",
    "_ = evaluate_model(xgb_tuned, X_test, y_test, name=\"XGB + SMOTE (tuned)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance / explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(preprocessor, cat_cols, num_cols):\n",
    "    names = []\n",
    "    names.extend(num_cols)\n",
    "    ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "    names.extend(list(ohe.get_feature_names_out(cat_cols)))\n",
    "    return names\n",
    "\n",
    "def show_importances(pipeline, title):\n",
    "    prep = pipeline.named_steps[\"prep\"]\n",
    "    names = get_feature_names(prep, cat_cols, num_cols)\n",
    "    clf = pipeline.named_steps[\"clf\"]\n",
    "    if hasattr(clf, \"feature_importances_\"):\n",
    "        imp = pd.Series(clf.feature_importances_, index=names).sort_values(ascending=False)\n",
    "        top20 = imp.head(20)\n",
    "        display(top20)\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.barplot(x=top20.values, y=top20.index, orient=\"h\")\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Model has no feature_importances_ attribute.\")\n",
    "\n",
    "# Show on tuned XGB (if tuned), else on RF+SMOTE\n",
    "try:\n",
    "    show_importances(xgb_tuned, \"Top Predictors — XGB + SMOTE (tuned)\")\n",
    "except NameError:\n",
    "    show_importances(rf_smote, \"Top Predictors — RF + SMOTE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Clinical Interpretation & Decision Support\n",
    "\n",
    "- **Sensitivity first:** missing a high-risk patient is a lost prevention opportunity. Tune threshold for desired recall (e.g., 0.75) and monitor precision to manage workload.  \n",
    "- **Actionability:** high-risk flag at discharge → care coordination outreach in 48–72 hours; medication reconciliation; early clinic visit; home health referral when appropriate.  \n",
    "- **Governance:** establish clinical oversight, periodic performance review, fairness checks across subgroups (age, sex, insurance), and calibration monitoring.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold tuning utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_sweep(y_true, scores, grid=np.linspace(0.1, 0.9, 9)):\n",
    "    rows = []\n",
    "    for t in grid:\n",
    "        pred = (scores >= t).astype(int)\n",
    "        rows.append({\n",
    "            \"threshold\": t,\n",
    "            \"precision\": precision_score(y_true, pred),\n",
    "            \"recall\": recall_score(y_true, pred),\n",
    "            \"f1\": f1_score(y_true, pred),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Example with tuned XGB scores if available (falls back gracefully)\n",
    "try:\n",
    "    if hasattr(xgb_tuned.named_steps[\"clf\"], \"predict_proba\"):\n",
    "        s = xgb_tuned.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        s = xgb_tuned.decision_function(X_test)\n",
    "except NameError:\n",
    "    if hasattr(rf_smote.named_steps[\"clf\"], \"predict_proba\"):\n",
    "        s = rf_smote.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        s = rf_smote.decision_function(X_test)\n",
    "\n",
    "sweep = threshold_sweep(y_test, s)\n",
    "display(sweep)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.lineplot(data=sweep, x=\"threshold\", y=\"recall\", marker=\"o\", label=\"Recall\")\n",
    "sns.lineplot(data=sweep, x=\"threshold\", y=\"precision\", marker=\"o\", label=\"Precision\")\n",
    "sns.lineplot(data=sweep, x=\"threshold\", y=\"f1\", marker=\"o\", label=\"F1\")\n",
    "plt.title(\"Threshold tuning (precision–recall trade-off)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Save Artifacts & Next Steps\n",
    "\n",
    "**Artifacts.** Save fully-fitted pipelines (preprocessing included) for downstream scoring.  \n",
    "**Next steps.** Calibration, subgroup analysis, prospective validation, and operational integration in the discharge workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, joblib\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "saved = {}\n",
    "# Save best candidates if they exist; ignore if not fitted in this session\n",
    "for name, pipe in [\n",
    "    (\"rf_smote\", 'rf_smote'),\n",
    "    (\"rf_under\", 'rf_under'),\n",
    "    (\"xgb_smote\", 'xgb_smote'),\n",
    "    (\"xgb_tuned\", 'xgb_tuned'),\n",
    "]:\n",
    "    try:\n",
    "        obj = globals()[pipe]\n",
    "        joblib.dump(obj, f\"artifacts/{name}.joblib\")\n",
    "        saved[name] = \"saved\"\n",
    "    except Exception as e:\n",
    "        saved[name] = f\"skip ({e.__class__.__name__})\"\n",
    "\n",
    "saved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test partition\n",
    "\n",
    "We use a stratified split to preserve the outcome rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling strategy\n",
    "\n",
    "Rationale  \n",
    "Logistic Regression offers transparency for clinical stakeholders and supports coefficient based interpretation.  \n",
    "Random Forest and Gradient Boosting often improve predictive performance on tabular data.\n",
    "\n",
    "Preprocessing  \n",
    "Numeric imputation uses median.  \n",
    "Categorical imputation uses most frequent value followed by one hot encoding.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"LogReg_balanced\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=300, random_state=42, n_jobs=-1, class_weight=\"balanced\"\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "pipelines = {\n",
    "    name: Pipeline(steps=[(\"preprocess\", preprocess), (\"clf\", clf)])\n",
    "    for name, clf in models.items()\n",
    "}\n",
    "list(pipelines.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting and core evaluation\n",
    "\n",
    "We report AUROC and AUPRC.  \n",
    "We print a full classification report and a confusion matrix.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "reports = {}\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    if hasattr(pipe.named_steps[\"clf\"], \"predict_proba\"):\n",
    "        proba = pipe.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        proba = pipe.decision_function(X_test)\n",
    "\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "    au\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
