{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hospital Readmission Prediction\n",
    "\n",
    "Clinical and economic context  \n",
    "Thirty day readmissions are a priority quality metric in value based care. Avoidable readmissions generate penalties and represent missed opportunities for safe transitions. A practical predictive model can support discharge planning and early outreach to high risk individuals.\n",
    "\n",
    "Repository  \n",
    "https://github.com/albertokabore/Hospital-Readmission-Prediction\n",
    "\n",
    "Dataset  \n",
    "`data/hospital_readmissions_30k.csv`  \n",
    "\n",
    "Outcome  \n",
    "`readmitted_30_days` with values Yes or No\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, StratifiedKFold, cross_val_score\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Environment and imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project overview\n",
    "\n",
    "Goal  \n",
    "Estimate the probability of a thirty day readmission at the time of discharge using routinely collected features.\n",
    "\n",
    "Clinical use  \n",
    "Flag high risk patients for post discharge calls, early clinic visits, medication review, and home care referrals.\n",
    "\n",
    "Success criteria  \n",
    "Balanced performance that supports early intervention. We report AUROC and AUPRC due to class imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and outcome definition\n",
    "DATA_PATH = Path(\"data\")\n",
    "FILE_NAME = \"hospital_readmissions_30k.csv\"\n",
    "TARGET = \"readmitted_30_days\"\n",
    "\n",
    "csv_path = DATA_PATH / FILE_NAME\n",
    "assert csv_path.exists(), f\"Dataset not found at {csv_path}. Place the CSV under data/.\"\n",
    "\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description and quality review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema and missing values\n",
    "buf = []\n",
    "df.info(buf=buf.append)\n",
    "print(\"\\n\".join(buf))\n",
    "\n",
    "print(\"\\nMissing values by column (top twenty):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "print(\"\\nOutcome distribution:\")\n",
    "print(df[TARGET].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome balance review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw = df[TARGET].astype(str).str.strip().str.title()\n",
    "pos_rate = (y_raw == \"Yes\").mean()\n",
    "print(f\"Positive rate Yes: {pos_rate:.3f}\")\n",
    "\n",
    "fig = plt.figure()\n",
    "y_raw.value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Outcome distribution\")\n",
    "plt.xlabel(TARGET)\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target cleaning and feature catalog\n",
    "\n",
    "We map Yes to one and No to zero.  \n",
    "We identify numeric and categorical predictors for preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_raw.map({\"Yes\": 1, \"No\": 0}).astype(int)\n",
    "X = df.drop(columns=[TARGET])\n",
    "\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "print(f\"Categorical columns: {len(cat_cols)}\")\n",
    "print(f\"Numeric columns: {len(num_cols)}\")\n",
    "print(\"Sample categoricals:\", cat_cols[:8])\n",
    "print(\"Sample numerics:\", num_cols[:8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis that informs modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric summary\n",
    "display(X[num_cols].describe(percentiles=[0.01, 0.25, 0.5, 0.75, 0.99]).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected numeric distributions if present\n",
    "for col in [\"age\", \"length_of_stay\", \"bmi\", \"cholesterol\", \"medication_count\"]:\n",
    "    if col in X.columns:\n",
    "        fig = plt.figure()\n",
    "        X[col].hist(bins=30)\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"count\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected categorical profiles if present\n",
    "for col in [\"gender\", \"diabetes\", \"hypertension\", \"discharge_destination\"]:\n",
    "    if col in X.columns:\n",
    "        print(f\"\\nTop values for {col}\")\n",
    "        print(X[col].value_counts(dropna=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test partition\n",
    "\n",
    "We use a stratified split to preserve the outcome rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling strategy\n",
    "\n",
    "Rationale  \n",
    "Logistic Regression offers transparency for clinical stakeholders and supports coefficient based interpretation.  \n",
    "Random Forest and Gradient Boosting often improve predictive performance on tabular data.\n",
    "\n",
    "Preprocessing  \n",
    "Numeric imputation uses median.  \n",
    "Categorical imputation uses most frequent value followed by one hot encoding.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"LogReg_balanced\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=300, random_state=42, n_jobs=-1, class_weight=\"balanced\"\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "pipelines = {\n",
    "    name: Pipeline(steps=[(\"preprocess\", preprocess), (\"clf\", clf)])\n",
    "    for name, clf in models.items()\n",
    "}\n",
    "list(pipelines.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting and core evaluation\n",
    "\n",
    "We report AUROC and AUPRC.  \n",
    "We print a full classification report and a confusion matrix.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "reports = {}\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    if hasattr(pipe.named_steps[\"clf\"], \"predict_proba\"):\n",
    "        proba = pipe.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        proba = pipe.decision_function(X_test)\n",
    "\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "    au\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
